{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "d5d6b13d-10a1-45be-a470-81a3e8a0f6ee"
    }
   },
   "source": [
    "# Facultad Regional Villa María\n",
    "\n",
    "## 5to año - Ingeniería en Sistemas de Información\n",
    "\n",
    "### Introducción al Aprendizaje por Refuerzos\n",
    "\n",
    "* Introducción. Modelo Agente Entorno. Agente Situado. Arquitectura Actor-Crítico.\n",
    "* Aprendizaje por Refuerzos. Elementos. Ciclo del Aprendizaje por Refuerzos. Definición Formal.\n",
    "* Procesos de Decisión de Markov. Función de Valor. Ecuación de Bellman. Optimalidad.\n",
    "* Aproximaciones al Aprendizaje. Model Free y Model Based.\n",
    "    * Iteración de Política.\n",
    "    * Iteración de Valor.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción: Entidad Inteligente -> Agente Situado\n",
    "* El desarrollo de la inteligencia requiere que la entidad o el agente esté situada/o en un entorno **(Measuring universal intelligence: Towards an anytime intelligence test, Hernandez-Orallo & Dowe, Artificial Intelligence, 2010).**\n",
    "![](images/Situated Agent.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent-Environment Framework\n",
    "* El agente y su entorno interactúan a través de la ejecución de acciones, observación de estados y señales de reward (recompensa). La inteligencia tendrá efecto sólo si el agente tiene claramente definidos objetivos o metas que persigue activamente mientras ocurre la interacción.\n",
    "![](images/AE Interaction.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arquitectura Actor-Crítico\n",
    "![](images/RL Diagram.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aprendizaje por Refuerzos\n",
    "\n",
    "* La toma de decisiones secuencial involucra aprender sobre nuestro entorno y elegir acciones que maximizan el retorno esperado. El RL computacional, inspirado por estas ideas, las formalizo y produjo un impacto importante en robótica, machine learning y neurociencias.\n",
    "\n",
    "* El Aprendizaje por Refuerzos (RL) consiste en un agente que se encuentra en algún estado $s \\in S$ inmerso en un entorno $E$ y toma acciones $a \\in A$ en busca de una meta. El agente puede ser modelado formalmente como una función f, que toma un  historial de interacción como entrada, y devuelve una acción a tomar. Una manera conveniente para representar el agente es una medida de probabilidad sobre el set A de acciones, en base a un historial de interacción: $$ f(a_{n}|s_{1}a_{1} r_{2} s_{2}a_{2}...r_{n}s_{n}) $$ que representa la probabilidad de la acción a en el ciclo n dado un historial de interacción.\n",
    "\n",
    "* Problema RL: ¿Cómo el agente produce la distribución de probabilidad sobre las acciones?\n",
    "\n",
    "* Dilema de exploración - explotación: debido a que el Agente no recibe ejemplos de entrenamiento, debe probar alternativas, procesar los resultados de sus acciones y modificar su comportamiento en algún sentido. ¿Cuándo explotar este conocimiento vs. cuándo probar nuevas estrategias?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elementos del Aprendizaje por Refuerzos\n",
    "![](images/RL Elements.png)\n",
    "\n",
    "* **Policy (Política): **\n",
    "\n",
    "Una política define la manera de comportarse de un agente, en cualquier momento de tiempo dado. Basicamente, es un mapeo de un estado o percepción s a una acción a, pudiendo ser estocásticas.\n",
    "\n",
    "* **Reward Function (Función de Recompensa)**\n",
    "\n",
    "Define cuantitativamente el objetivo del agente. Es un mapeo de un par estado-acción a un número real que indica \"cuán deseable\" es ejecutar dicha acción en ese estado. Asimismo, el único objetivo del agente es maximizar la recompensa total que recibe a lo large del tiempo. Cabe mencionar que, si bien la función de reward no puede ser alterada por el agente, provee las bases para cambiar la política del mismo.\n",
    "\n",
    "* **Value function (Función de Valor)**\n",
    "\n",
    "La función de valor se diferencia de la función de reward en el sentido de que indica \"cuán deseable\" es, a largo plazo, ejecutar una acción en un determinado estado. Así, el valor de un estado s es la cantidad total de reward que el agente espera obtener a futuro comenzando la interacción en el estado s.\n",
    "\n",
    "* **Environment (Entorno)**\n",
    "\n",
    "El entorno se encuentra constitutido por todo aquel elemento (real o simulado) que el agente no puede controlar. Es con quién el agente interactúa a partir de la ejecución de acciones de control.\n",
    "\n",
    "## Ciclo del Aprendizaje por Refuerzos\n",
    "![](images/RL Cycle.png)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "84a1b72e-5d2e-4343-a014-0fcfee9373e4"
    }
   },
   "source": [
    "### Definición formal\n",
    "\n",
    "* Si el problema de RL dado tiene un conjunto finito de estados y acciones y satisface la propiedad de Markov entonces puede definirse como un Proceso de Decisión de Markov\n",
    "\n",
    "\\begin{equation}\n",
    "MDPFinito = (S, A, P(.), R(.), γ)\n",
    "\\end{equation}\n",
    "\n",
    "donde\n",
    "\n",
    "$$ S = {s_{1}, s_{2}, ..., s_{n}} $$\n",
    "es un conjunto finito de estados.\n",
    "$$ A = {a_{1}, a_{2}, ..., a_{m}} $$\n",
    "es un conjunto finito de acciones.\n",
    "$$ P_{a}(s,s') = P(s_{t+1} = s | s_{t} = s, a_{t} = a) $$ \n",
    "es la probabilidad de que la acción a tomada en tiempo t y en estado s lleve al agente al estado s' en tiempo t+1\n",
    "$$ R_{a}(s,s') $$\n",
    "es la recompensa inmediata recibido tras transicionar, luego de tomar la acción a, desde el estado s al estado s'\n",
    "$$\\gamma \\in  [0,1]$$ \n",
    "es el factor de descuento, representando la diferencia en la importancia de la recompensa a corto plazo vs la recompensa a largo plazo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/mdp_example.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "197f95d9-38cd-4f22-830a-1c484037b895"
    }
   },
   "source": [
    "* Un episodio (instancia) de este MDP forma una secuencia finita \n",
    "$$s_{0}, a_{0}, r_{1}, s_{1}, a_{1}, r_{2}, s_{2}, ... , s_{n-1}, a_{n-1}, r_{n}, s_{n} $$ \n",
    "donde $$s_{n}$$\n",
    "es un estado final (o n es el tiempo de corte).\n",
    "\n",
    "* La recompensa total del episodio está dado por \n",
    "$$ R = r_{1} + r_{2} + ... + r_{n} $$\n",
    "\n",
    "* En consecuencia, la recompensa a futuro partiendo del tiempo $t$ está dado por \n",
    "$$R_{t} = r_{t} + r_{t+1} + ... $$\n",
    "\n",
    "* Hay que considerar que el ambiente es estocástico en la mayor parte de los entornos reales y, por tanto, la recompensa suele diverger mientras más alejado se encuentre el instante de tiempo considerado. Es por esto que se utiliza un parámetro $γ$ llamado _factor de descuento_, para descontar el valor de las recompensas futuras. De esta manera,\n",
    "\n",
    "\\begin{equation} R_{t} = r_{t} + γr_{t+1} + γ^2r_{t+2} + γ^3r_{t+3} + ... = r_{t} + γ(r_{t+1} + γr_{t+2} + γ^2r_{t+3} ...) = r_{t} + γR_{t+1} \\end{equation}\n",
    "\n",
    "* Si utilizamos $γ=0$, el agente priorizará sólo la recompensa inmediata, mientras que $\\gamma=1$ hará que considere todas los recompensas de la misma manera, independientemente del momento en donde las reciba.\n",
    "![](images/RL Problem Statement.png)\n",
    "![](images/Policy Definition.png)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procesos de Decisión de Markov\n",
    "\n",
    "### Función de Valor\n",
    "\n",
    "* El valor de un estado es el retorno esperado por el agente, comenzando la interacción en dicho estado, dependiendo de la política ejecutada por el agente.\n",
    "\n",
    "![](images/Funcion de Estado Valor.png)\n",
    "\n",
    "* El valor de la ejecución de una acción en un estado es el retorno esperado por el agente, comenzando la interacción en dicho estado a partir de la ejecución de dicha acción, dependiendo de la política ejecutada por el agente.\n",
    "\n",
    "![](images/Funcion de Accion Valor.png)\n",
    "\n",
    "Una propiedad fundamental de las funciones de valor es que satisfacen ciertas propiedades recursivas. Para cualquier política  π y cualquier estado s, V(s) y Q(s,a) pueden ser definidas recursivamente en términos de la denominada *Ecuación de Bellman* ** (Bellman, 1957) **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ecuación de Bellman\n",
    "\n",
    "* La idea básica es:\n",
    "\n",
    "![](images/Retorno.png)\n",
    "\n",
    "* Entonces,\n",
    "\n",
    "![](images/Retorno - Valor.png)\n",
    "\n",
    "* O, sin el operador de valor esperado:\n",
    "\n",
    "![](images/Bellman Equation.png)\n",
    "\n",
    "La ecuación anterior refleja el hecho de que el valor de un estado se encuentra definido en términos de la recompensa inmediata y los valores de los estados siguientes ponderados en función de las probabilidades de transición, y adicionalmente un factor de descuento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ecuación de Optimalidad de Bellman\n",
    "\n",
    "La Ecuación de Optimalidad de Bellman refleja el hecho de que el Valor de un estado bajo la política óptima debe ser igual al retorno esperado para la mejor acción en dicho estado:\n",
    "\n",
    "![](images/Ecuacion de Optimalidad Valor.png)\n",
    "\n",
    "Al mismo tiempo, la acción óptima para un estado s dada la función de valor, puede obtenerse mediante:\n",
    "\n",
    "![](images/Accion Optima.png)\n",
    "\n",
    "La política anterior se denomina **Política Greedy**, dado que selecciona la mejor acción para cada estado, teniendo en cuenta la función de valor V(s). De manera análoga, la función de acción-valor óptima puede expresarse como:\n",
    "\n",
    "![](images/Accion Valor Optima.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aproximaciones para el aprendizaje de V y Q\n",
    "\n",
    "![](images/Aproximaciones al aprendizaje.png)\n",
    "\n",
    "### Model Based vs. Model Free\n",
    "\n",
    "* Model-free aprende Q/V directamente y presenta muy baja complejidad computacional.\n",
    "\n",
    "* Model-based aprende T y R y usa un algoritmo de planning para encontrar la política. Uso eficiente de los datos/experiencia. Alto costo computacional."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Programación Dinámica: Iteración de Valor e Iteración de Política (Model Based)\n",
    "\n",
    "#### Iteración de Valor\n",
    "\n",
    "![](images/Iteracion de Valor.png)\n",
    "\n",
    "#### Iteración de Política\n",
    "\n",
    "![](images/Iteracion de Politica.png)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "nbpresent": {
   "slides": {
    "0d01fc30-23a9-4dc7-a99a-309a23aa7a9b": {
     "id": "0d01fc30-23a9-4dc7-a99a-309a23aa7a9b",
     "prev": "899c419b-b69d-4a42-8c8f-ec9e170f2953",
     "regions": {
      "d7b7ed9a-ebe1-45b7-b520-ee8111741f6f": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "4951a012-93f0-4561-b2aa-f356d9fd10af",
        "part": "whole"
       },
       "id": "d7b7ed9a-ebe1-45b7-b520-ee8111741f6f"
      }
     }
    },
    "1265d14e-4373-4961-b094-fdc0f41bd665": {
     "id": "1265d14e-4373-4961-b094-fdc0f41bd665",
     "prev": "69ef8fab-1cf4-4791-8359-fbd8c36b87f5",
     "regions": {
      "60a1d8af-4d7e-49aa-923c-5bc0d4914c2c": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "c7d530e5-f080-4f70-9482-c4612911cbe3",
        "part": "whole"
       },
       "id": "60a1d8af-4d7e-49aa-923c-5bc0d4914c2c"
      }
     }
    },
    "1315de08-3be9-4fc0-81e0-acc069ac5044": {
     "id": "1315de08-3be9-4fc0-81e0-acc069ac5044",
     "prev": null,
     "regions": {
      "b47d0e6d-4dcb-4a20-8e5e-874847ad2b76": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "d5d6b13d-10a1-45be-a470-81a3e8a0f6ee",
        "part": "whole"
       },
       "id": "b47d0e6d-4dcb-4a20-8e5e-874847ad2b76"
      }
     }
    },
    "1809123f-e0c6-4859-bc21-f3b5dc441a1b": {
     "id": "1809123f-e0c6-4859-bc21-f3b5dc441a1b",
     "prev": "3ad98c91-7a86-4a2a-9ecf-cfc6db0d3916",
     "regions": {
      "9c137fb8-1b4f-427e-9b34-49632cbebe6d": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "037b358e-6d28-4df4-ae9d-974f8775e00e",
        "part": "whole"
       },
       "id": "9c137fb8-1b4f-427e-9b34-49632cbebe6d"
      }
     }
    },
    "1c00d850-e4dc-4916-bbe5-b275c71d185b": {
     "id": "1c00d850-e4dc-4916-bbe5-b275c71d185b",
     "prev": "982cfab9-3c43-45c9-9733-6e3c27538085",
     "regions": {
      "27107d62-642d-48d1-96c8-f9b6e21001d9": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "9da47f7b-28d6-44cb-bac2-daae14fab987",
        "part": "whole"
       },
       "id": "27107d62-642d-48d1-96c8-f9b6e21001d9"
      }
     }
    },
    "223fdf1f-941d-4667-819b-4082691bb812": {
     "id": "223fdf1f-941d-4667-819b-4082691bb812",
     "prev": "6afb007f-1120-46a8-8c15-2cdaa7286dab",
     "regions": {
      "3f59bb53-c37b-4f27-bc1e-1ab27bc75d99": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "58ec6acb-8f4f-4fda-af22-9f4703e72336",
        "part": "whole"
       },
       "id": "3f59bb53-c37b-4f27-bc1e-1ab27bc75d99"
      }
     }
    },
    "313101ba-a6ea-4985-b56a-7e5faeb4ef11": {
     "id": "313101ba-a6ea-4985-b56a-7e5faeb4ef11",
     "prev": "90bfd2ff-9a21-4de9-8584-dd17db513b9b",
     "regions": {
      "00901c26-d4cf-4a49-8a0e-4e61005f043c": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "2be788a6-2235-491e-aab5-0bb567fe525d",
        "part": "whole"
       },
       "id": "00901c26-d4cf-4a49-8a0e-4e61005f043c"
      }
     }
    },
    "3194ed44-3f5e-49b0-bdb0-38553756e922": {
     "id": "3194ed44-3f5e-49b0-bdb0-38553756e922",
     "prev": "f6cecdf6-a875-43e5-8544-93b4f9abb66d",
     "regions": {
      "541d2ce3-01f2-49f4-a6d1-f41765d0a18c": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "ef536408-da22-4ef2-808e-2a65e7081661",
        "part": "whole"
       },
       "id": "541d2ce3-01f2-49f4-a6d1-f41765d0a18c"
      }
     }
    },
    "3ad98c91-7a86-4a2a-9ecf-cfc6db0d3916": {
     "id": "3ad98c91-7a86-4a2a-9ecf-cfc6db0d3916",
     "prev": "d6d405a0-dfde-4a37-a754-7db5e780e0af",
     "regions": {
      "a200fdd8-1279-4bbb-9cba-eac12cf5dbcb": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "c4915b91-8222-4388-b0bc-3bb6a4d87b54",
        "part": "whole"
       },
       "id": "a200fdd8-1279-4bbb-9cba-eac12cf5dbcb"
      }
     }
    },
    "3ea64685-7182-46a8-b427-641f90be1dc9": {
     "id": "3ea64685-7182-46a8-b427-641f90be1dc9",
     "prev": "dcf0e1b4-2b46-4603-bb28-5f8e80ffd702",
     "regions": {
      "d14104e3-1e91-4507-be35-db71a6dd41a8": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "eb46d21c-4caa-42a9-a197-4d64c603fd9b",
        "part": "whole"
       },
       "id": "d14104e3-1e91-4507-be35-db71a6dd41a8"
      }
     }
    },
    "4257ba12-3eec-48b3-8dc4-a92664887a5d": {
     "id": "4257ba12-3eec-48b3-8dc4-a92664887a5d",
     "prev": "92e07c6c-11e0-4795-bda1-abe9ddfd4d02",
     "regions": {
      "efaedb93-d56a-491b-8660-b8e2e5b07519": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "9bc1fb76-8a78-4f38-a718-38d1e15cc1b3",
        "part": "whole"
       },
       "id": "efaedb93-d56a-491b-8660-b8e2e5b07519"
      }
     }
    },
    "4f4a9683-905f-4595-9760-d56a847ae47c": {
     "id": "4f4a9683-905f-4595-9760-d56a847ae47c",
     "prev": "4257ba12-3eec-48b3-8dc4-a92664887a5d",
     "regions": {
      "c00eb85e-4e9e-48ac-8119-2a14a98c2042": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "6bee5ed5-2110-428b-9f5b-feb464858aaf",
        "part": "whole"
       },
       "id": "c00eb85e-4e9e-48ac-8119-2a14a98c2042"
      }
     }
    },
    "69ef8fab-1cf4-4791-8359-fbd8c36b87f5": {
     "id": "69ef8fab-1cf4-4791-8359-fbd8c36b87f5",
     "prev": "223fdf1f-941d-4667-819b-4082691bb812",
     "regions": {
      "58b36bb4-8aa5-44e0-b88d-db85a5ad1e5c": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "a61ee6dd-76b9-4ed4-93e7-e28a25ae4490",
        "part": "whole"
       },
       "id": "58b36bb4-8aa5-44e0-b88d-db85a5ad1e5c"
      }
     }
    },
    "6afb007f-1120-46a8-8c15-2cdaa7286dab": {
     "id": "6afb007f-1120-46a8-8c15-2cdaa7286dab",
     "prev": "dd511c07-9814-43e5-b7c0-31151b3582e9",
     "regions": {
      "d3c11af7-2f8c-4b6f-af02-8e5ab8a114db": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "e118cd6c-e993-4a82-a052-caeb13fb8cad",
        "part": "whole"
       },
       "id": "d3c11af7-2f8c-4b6f-af02-8e5ab8a114db"
      }
     }
    },
    "6c974a58-be8c-42b2-a4e5-e31607f31727": {
     "id": "6c974a58-be8c-42b2-a4e5-e31607f31727",
     "prev": "1c00d850-e4dc-4916-bbe5-b275c71d185b",
     "regions": {
      "1b3a3c08-25e5-40a5-8faf-2855fea2e3ac": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "f417f2ff-615d-4adc-bb45-0482f34e77c0",
        "part": "whole"
       },
       "id": "1b3a3c08-25e5-40a5-8faf-2855fea2e3ac"
      }
     }
    },
    "7d5b2ad9-38cb-4ce1-8c24-7774740b8710": {
     "id": "7d5b2ad9-38cb-4ce1-8c24-7774740b8710",
     "prev": "cef2e9fb-fb0c-4d2c-9264-fa08d3de7788",
     "regions": {
      "17c4f751-c034-4d71-9d8b-eaa8bad1602f": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "197f95d9-38cd-4f22-830a-1c484037b895",
        "part": "whole"
       },
       "id": "17c4f751-c034-4d71-9d8b-eaa8bad1602f"
      }
     }
    },
    "899c419b-b69d-4a42-8c8f-ec9e170f2953": {
     "id": "899c419b-b69d-4a42-8c8f-ec9e170f2953",
     "prev": "6c974a58-be8c-42b2-a4e5-e31607f31727",
     "regions": {
      "0d0ff77c-47e7-4ecf-8542-348d395aa416": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "96467e64-3610-4e91-8034-b35e87ac68fb",
        "part": "whole"
       },
       "id": "0d0ff77c-47e7-4ecf-8542-348d395aa416"
      }
     }
    },
    "8ee0867a-0485-4903-9e16-0b1a83bad931": {
     "id": "8ee0867a-0485-4903-9e16-0b1a83bad931",
     "prev": "9b077531-fbbf-4d74-8bd4-55550025f933",
     "regions": {
      "26cefc3d-e27f-46ec-be1d-e8c0849eb199": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "9248f5e9-f98c-458a-ae3a-71512b071a5b",
        "part": "whole"
       },
       "id": "26cefc3d-e27f-46ec-be1d-e8c0849eb199"
      }
     }
    },
    "90bfd2ff-9a21-4de9-8584-dd17db513b9b": {
     "id": "90bfd2ff-9a21-4de9-8584-dd17db513b9b",
     "prev": "adb231cc-0652-40e4-bc3c-9ce52082cb6b",
     "regions": {
      "83eddba8-c706-49a3-89bd-b510bc2c5008": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "6bdd9f90-0795-44d8-a18d-c13301520398",
        "part": "whole"
       },
       "id": "83eddba8-c706-49a3-89bd-b510bc2c5008"
      }
     }
    },
    "90defec3-5b4d-470f-a68d-6a6fae9ebbec": {
     "id": "90defec3-5b4d-470f-a68d-6a6fae9ebbec",
     "prev": "8ee0867a-0485-4903-9e16-0b1a83bad931",
     "regions": {
      "fe8179b7-977e-48dc-be62-abf41f233a62": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "1d808ce4-f5b3-4c18-818d-04c00ee0d322",
        "part": "whole"
       },
       "id": "fe8179b7-977e-48dc-be62-abf41f233a62"
      }
     }
    },
    "92e07c6c-11e0-4795-bda1-abe9ddfd4d02": {
     "id": "92e07c6c-11e0-4795-bda1-abe9ddfd4d02",
     "prev": "0d01fc30-23a9-4dc7-a99a-309a23aa7a9b",
     "regions": {
      "fb6e6866-7208-41e1-b6ba-9450762a1241": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "a3de943f-ece8-4dc5-8221-6611d4b59541",
        "part": "whole"
       },
       "id": "fb6e6866-7208-41e1-b6ba-9450762a1241"
      }
     }
    },
    "982cfab9-3c43-45c9-9733-6e3c27538085": {
     "id": "982cfab9-3c43-45c9-9733-6e3c27538085",
     "prev": "313101ba-a6ea-4985-b56a-7e5faeb4ef11",
     "regions": {
      "daed9365-6bd9-4bcb-a676-208bb12b4361": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "4c8e853f-b925-4f45-82f2-36069d4f094b",
        "part": "whole"
       },
       "id": "daed9365-6bd9-4bcb-a676-208bb12b4361"
      }
     }
    },
    "9b077531-fbbf-4d74-8bd4-55550025f933": {
     "id": "9b077531-fbbf-4d74-8bd4-55550025f933",
     "prev": "1809123f-e0c6-4859-bc21-f3b5dc441a1b",
     "regions": {
      "3ec109fc-1ac8-4762-847e-5e6465f9cae8": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "570ee83e-6db4-4a0e-b4ca-76c9665199d7",
        "part": "whole"
       },
       "id": "3ec109fc-1ac8-4762-847e-5e6465f9cae8"
      }
     }
    },
    "adb231cc-0652-40e4-bc3c-9ce52082cb6b": {
     "id": "adb231cc-0652-40e4-bc3c-9ce52082cb6b",
     "prev": "3ea64685-7182-46a8-b427-641f90be1dc9",
     "regions": {
      "da3e4bfe-8e1c-4315-bb8d-38def529ab4c": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "464da1eb-7686-4f7d-a94f-fd4f4b3ae2e1",
        "part": "whole"
       },
       "id": "da3e4bfe-8e1c-4315-bb8d-38def529ab4c"
      }
     }
    },
    "c4d9cb29-6062-4d67-bacf-309165899909": {
     "id": "c4d9cb29-6062-4d67-bacf-309165899909",
     "prev": "f3ec050f-3d84-4833-87a4-3186460564fb",
     "regions": {
      "4429e8a1-ec45-4949-923e-5e7b08049d2d": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "8757fda7-751c-4dcd-80c7-fa4097aa62a3",
        "part": "whole"
       },
       "id": "4429e8a1-ec45-4949-923e-5e7b08049d2d"
      }
     }
    },
    "cbf62be1-d44f-43e8-a594-bba802494845": {
     "id": "cbf62be1-d44f-43e8-a594-bba802494845",
     "prev": "c4d9cb29-6062-4d67-bacf-309165899909",
     "regions": {
      "f304038b-504c-46f6-b03c-fc564190e993": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "14bef84c-7b2e-46b7-ac4f-18b9854d609e",
        "part": "whole"
       },
       "id": "f304038b-504c-46f6-b03c-fc564190e993"
      }
     }
    },
    "cef2e9fb-fb0c-4d2c-9264-fa08d3de7788": {
     "id": "cef2e9fb-fb0c-4d2c-9264-fa08d3de7788",
     "prev": "1315de08-3be9-4fc0-81e0-acc069ac5044",
     "regions": {
      "dc60dfcf-1616-4f16-82a0-cb0fade4e740": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "84a1b72e-5d2e-4343-a014-0fcfee9373e4",
        "part": "whole"
       },
       "id": "dc60dfcf-1616-4f16-82a0-cb0fade4e740"
      }
     }
    },
    "d6d405a0-dfde-4a37-a754-7db5e780e0af": {
     "id": "d6d405a0-dfde-4a37-a754-7db5e780e0af",
     "prev": "4f4a9683-905f-4595-9760-d56a847ae47c",
     "regions": {
      "cb634b1b-130b-4ddc-a273-f4d4b766feca": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "b0f69589-df64-4288-985f-2cec5d01472f",
        "part": "whole"
       },
       "id": "cb634b1b-130b-4ddc-a273-f4d4b766feca"
      }
     }
    },
    "dcf0e1b4-2b46-4603-bb28-5f8e80ffd702": {
     "id": "dcf0e1b4-2b46-4603-bb28-5f8e80ffd702",
     "prev": "e67834a8-52ef-48d9-90b7-a291acb99e4b",
     "regions": {
      "0789a766-9218-417b-8534-24a6d4772988": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "9d90f76f-96f5-4405-a1f5-4cf4eb5522fd",
        "part": "whole"
       },
       "id": "0789a766-9218-417b-8534-24a6d4772988"
      }
     }
    },
    "dd511c07-9814-43e5-b7c0-31151b3582e9": {
     "id": "dd511c07-9814-43e5-b7c0-31151b3582e9",
     "prev": "eab010b8-7397-4b90-835d-bf2e90bff56c",
     "regions": {
      "bb5d1405-461c-4569-86dd-b21c981872ed": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "d7e940c4-4812-411a-94d3-7279c2de20cc",
        "part": "whole"
       },
       "id": "bb5d1405-461c-4569-86dd-b21c981872ed"
      }
     }
    },
    "e67834a8-52ef-48d9-90b7-a291acb99e4b": {
     "id": "e67834a8-52ef-48d9-90b7-a291acb99e4b",
     "prev": "cbf62be1-d44f-43e8-a594-bba802494845",
     "regions": {
      "9be8c217-3af4-451c-833e-fc9e910cb804": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "ec118c50-e3fc-4dd2-9376-3e598f98167b",
        "part": "whole"
       },
       "id": "9be8c217-3af4-451c-833e-fc9e910cb804"
      }
     }
    },
    "eab010b8-7397-4b90-835d-bf2e90bff56c": {
     "id": "eab010b8-7397-4b90-835d-bf2e90bff56c",
     "prev": "7d5b2ad9-38cb-4ce1-8c24-7774740b8710",
     "regions": {
      "31363f19-2d8a-4bb1-9c82-5125bf553b08": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "1b6580a7-ed0d-40c8-b2a7-a413193deae3",
        "part": "whole"
       },
       "id": "31363f19-2d8a-4bb1-9c82-5125bf553b08"
      }
     }
    },
    "f3ec050f-3d84-4833-87a4-3186460564fb": {
     "id": "f3ec050f-3d84-4833-87a4-3186460564fb",
     "prev": "1265d14e-4373-4961-b094-fdc0f41bd665",
     "regions": {
      "9dbd9105-2145-44ca-8fb6-f23ff8438a46": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "7770a42f-6089-4f0a-85a9-025f72d3ad5a",
        "part": "whole"
       },
       "id": "9dbd9105-2145-44ca-8fb6-f23ff8438a46"
      }
     }
    },
    "f6cecdf6-a875-43e5-8544-93b4f9abb66d": {
     "id": "f6cecdf6-a875-43e5-8544-93b4f9abb66d",
     "prev": "90defec3-5b4d-470f-a68d-6a6fae9ebbec",
     "regions": {
      "8001bab8-0471-4f0a-9d92-c14df7dfea7d": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "945892c8-340a-4bf8-bbcf-1aa29c546187",
        "part": "whole"
       },
       "id": "8001bab8-0471-4f0a-9d92-c14df7dfea7d"
      }
     }
    }
   },
   "themes": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
